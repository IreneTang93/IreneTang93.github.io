---
---
@article{RN1312,
   author = {Fan*, Z. and Tang*, X. and Li#, X. and Khan, SZ and Li#, Z.},
   title = {Quantifying cloud elasticity with container-based autoscaling},
   journal = {Future Generation Computer Systems},
   pages = {672-681},
   url = {https://www.sciencedirect.com/science/article/abs/pii/S0167739X18307842},
   year = {2019},
   type = {Journal Article},
   abbr = {FGCS},
   pdf = {autoscaler/autoscaler_FGCS.pdf},
   abstract = {{Containers have been a pervasive approach to help rapidly develop, test and update the Internet of Things applications (IoT). The autoscaling of containers can adaptively allocate computing resources for various data volumes over time. Therefore, elasticity, a critical feature of a cloud platform, is significant to measure the performance of lightweight containers. In this paper, we propose a framework with container auto-scaler. It monitors containers resource usage and accordingly scales in or scales out containers in need. Further, we define elasticity mathematically in order to quantify the cloud elasticity using the proposed framework. Extensive experiments are carried out with different workload modes, workload durations, and scaling cooldown period of times. Experiment results show that the framework captures the workload variation firmly with a very short delay. We also find out that the cloud platform shows the best elasticity in repeat workload mode due to its recurring and predictable feature. Finally, we discover the length of the cooldown period should be properly set up in order to balance system stability and good elasticity.}},
   selected = {true}
}

@article{RN1312,
   author = {Tang*, X. and Fan*, Z. and Li#, X. and Khan, SZ and Li#, Z.},
   title = {Quantifying cloud elasticity with container-based autoscaling},
   conference = {IEEE PiCom},
   doi = {10.1109/DASC-PICom-DataCom-CyberSciTec.2017.143},
   url = {https://ieeexplore.ieee.org/abstract/document/8328487/authors#authors},
   year = {2018},
   type = {Conference Article},
   abbr = {IEEE Conf},
   pdf = {autoscaler/autoscaler_v1.pdf},
   abstract = {{Containers have been a pervasive approach to help rapidly develop, test and update the Internet of Things applications (IoT). The autoscaling of containers can adaptively allocate computing resources for various data volumes over time. Therefore, elasticity, a critical feature of a cloud platform, is significant to measure the performance of lightweight containers. In this paper, we propose a framework with container auto-scaler. It monitors containers resource usage and accordingly scales in or scales out containers in need. Further, we define elasticity mathematically in order to quantify the cloud elasticity using the proposed framework. Extensive experiments are carried out with different workload modes, workload durations, and scaling cool-down period of times. Experiment results show that the framework captures the workload variation firmly with a very short delay. We also find out that the cloud platform shows the best elasticity in repeat workload mode due to its recurring and predictable feature. Finally, we discover the length of the cool-down period should be properly set up in order to balance system stability and good elasticity.}},
   selected = {true}
}

@article{RN1312,
   author = {Tang*, X. and Li#, Z. and Chen, Y. },
   title = {A Night Image Enhancement Algorithm Based on Guided Filtering},
   doi = {10.1109/DASC-PICom-DataCom-CyberSciTec.2017.143},
   url = {https://link.springer.com/chapter/10.1007/978-981-10-3530-2_35},
   year = {2016},
   type = {Conference Article},
   abbr = {Springer},
   pdf = {nightimage.pdf},
   abstract = {{Colored night images lead to various problems in real life, such as low dynamic range, detail blurring and so on, which are waiting to be solved. For this reason, it proposes an algorithm for night image enhancement based on guided filtering in the paper. This image process includes three main steps. Firstly, by transforming to HVS color space, the targeted image is separated coarsely into two imagesâ€”base layer image and detail layer image in the result of guided filtering. In the second step, the base layer and detail layer are processed by different strategies selectively and respectively to lighten the whole, but remain details as much as possible. Eventually, the base layer, which has been previously increased contrast, is added detail layer to keep the details and margins. The result image can be retained after reverting to the original color space. Our result illustrates the comparison among result images and images enhanced by other methods, which obviously proves that the algorithm in our paper can obtain relatively better results in the ways of detail enhancement and color fidelity.}},
   selected = {true}
}